{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84b81fe",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a3f51a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e826c57",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc0c8c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1695a8ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config('spark.executor.memory', '8G').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd3a522e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cnae_path = './data/CNAE/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c30aec",
   "metadata": {},
   "source": [
    "# Leitura dos arquivos com schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19f28287",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema1 = '_c0 STRING, _c1 STRING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "08f402f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_cnae = (spark.read\n",
    "    .format('csv')\n",
    "    .option('sep', ';')\n",
    "    .option('encoding', 'ISO-8859-1')\n",
    "     .schema(schema1)\n",
    "    .load(cnae_path + 'CNAE.csv')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bccce641",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|    _c0|                 _c1|\n",
      "+-------+--------------------+\n",
      "|0111301|    Cultivo de arroz|\n",
      "|0111302|    Cultivo de milho|\n",
      "|0111303|    Cultivo de trigo|\n",
      "|0111399|Cultivo de outros...|\n",
      "|0112101|Cultivo de algodã...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cnae.limit(5).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1cff6884",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cnae.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e6a7e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquivo 2\n",
    "schema2 = '_c0 STRING, _c1 STRING'\n",
    "read_options = {\n",
    "    'encoding': 'ISO-8859-1',\n",
    "    'sep': ';',  \n",
    "    'escape': \"\\\"\" ,\n",
    "}\n",
    "\n",
    "df_munic = (\n",
    "    spark.read\n",
    "    .format('csv')\n",
    "    .options(**read_options)\n",
    "    .schema(schema2)\n",
    "    .load(cnae_path + 'F.K03200$Z.D10710.MUNIC.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1725747d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_munic.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f0cf72ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| _c0|                 _c1|\n",
      "+----+--------------------+\n",
      "|0001|       GUAJARA-MIRIM|\n",
      "|0002|ALTO ALEGRE DOS P...|\n",
      "|0003|         PORTO VELHO|\n",
      "|0004|             BURITIS|\n",
      "|0005|           JI-PARANA|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_munic.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8632a31e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a61bf233",
   "metadata": {},
   "source": [
    "# Renomeando as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a5c7d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "| codigo| atividade_economica|\n",
      "+-------+--------------------+\n",
      "|0111301|    Cultivo de arroz|\n",
      "|0111302|    Cultivo de milho|\n",
      "|0111303|    Cultivo de trigo|\n",
      "|0111399|Cultivo de outros...|\n",
      "|0112101|Cultivo de algodã...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df_cnae\n",
    "    .withColumnRenamed('_c0', 'codigo')\n",
    "    .withColumnRenamed('_c1', 'atividade_economica')\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2efc9588",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|codigo|   nome_do_municipio|\n",
      "+------+--------------------+\n",
      "|  0001|       GUAJARA-MIRIM|\n",
      "|  0002|ALTO ALEGRE DOS P...|\n",
      "|  0003|         PORTO VELHO|\n",
      "|  0004|             BURITIS|\n",
      "|  0005|           JI-PARANA|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df_munic\n",
    "    .withColumnRenamed('_c0', 'codigo')\n",
    "    .withColumnRenamed('_c1', 'nome_do_municipio')\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6868d46",
   "metadata": {},
   "source": [
    "### Colunas e Expressões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de676cb",
   "metadata": {},
   "source": [
    "As colunas são a principal unidade de manipulação de dados do Spark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3624c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, round\n",
    "\n",
    "(\n",
    "    df_cnae.select('tconst', 'primaryTitle', 'runtimeMinutes', )\n",
    "    .withColumn(\"runtimeHours\", round(col('runTimeMinutes').cast('int') / 60, 3))\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b1e3c",
   "metadata": {},
   "source": [
    "Forma \"pandas\" de selecionar:\n",
    "\n",
    "1. `df.coluna`\n",
    "2. `df['coluna']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab96a42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles.select('tconst', 'primaryTitle', 'runtimeMinutes', )\n",
    "    .withColumn(\"runtimeHours\", df_titles['runtimeMinutes'].cast('int') / 60 )\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6547f68",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles.select('tconst', 'primaryTitle', 'runtimeMinutes', )\n",
    "    .withColumn(\"runtimeHours\", df_titles['runtimeMinutes'].cast('int') / 60 )\n",
    "    .withColumn(\"hours_plus2\", df_titles['runtimeHours'] + 2 )\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61650f63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles.select('tconst', 'primaryTitle', 'runtimeMinutes', )\n",
    "    .withColumn(\"runtimeHours\", col('runTimeMinutes').cast('int') / 60 )\n",
    "    .withColumn(\"hours_plus2\", col('runtimeHours') + 2 )\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb42fb",
   "metadata": {},
   "source": [
    "#### Expressões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bac86f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "(\n",
    "    df_titles.select('tconst', 'primaryTitle', 'runtimeMinutes', )\n",
    "    .withColumn(\"runtimeHours\", expr('round(cast(runTimeMinutes as INT) / 60, 3)') )\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b68d042",
   "metadata": {},
   "source": [
    "### Seleção de Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247279d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4bf0c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3192d054",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.select('tconst', 'primaryTitle', 'genres').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe8726",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "select_cols = [c for c in df_titles.columns if c.find('Title') != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61b52f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['tconst', 'primaryTitle', 'genres']\n",
    "df_titles.select(select_cols).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d84e3ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['primaryTitle', 'genres']\n",
    "df_titles.select('tconst', *cols).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68875d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.select('*').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfa0b55",
   "metadata": {},
   "source": [
    "Observações:\n",
    "* Podemos realizar operações sobre colunas selecionadas. \n",
    "* A ordem em que as colunas são selecionadas é a ordem em que elas vão ser inseridas no DataFrame resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434cf483",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import upper, expr\n",
    "\n",
    "df_titles.select('tconst', 'genres', expr('upper(primaryTitle) as primaryTitle')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6398eccb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.selectExpr('tconst', 'genres', 'upper(primaryTitle) as primaryTitle').show(10)\n",
    "df_titles.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd45f3",
   "metadata": {},
   "source": [
    "#### Selecionando valores distintos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b43416b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.dropDuplicates(subset=['startYear']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f59a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.select('startYear').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.dropDuplicates(subset=['startYear']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd02191",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67378a90",
   "metadata": {},
   "source": [
    "### Filtros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53292b89",
   "metadata": {},
   "source": [
    "Operadores lógicos:\n",
    "* e: &\n",
    "* ou: |\n",
    "* não: ~\n",
    "\n",
    "Para fazer o filtro, pode ser utilizado tanto a função `filter()` como `where()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcadfdd",
   "metadata": {},
   "source": [
    "#### Filtros com uma condição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f07bb8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles.filter(~(col('titleType') == 'movie'))\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5884539",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles.where(col('titleType') == 'movie')\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61040bf",
   "metadata": {},
   "source": [
    "#### Filtros com duas ou mais condições\n",
    "Cada uma das condições deve estar entre parênteses e separada por um operador lógico. Naturalmente, é possível também \"aninhar\" condições, seguindo essa mesma lógica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f6e469",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles.filter((col('titleType') == 'movie') & (col('runtimeMinutes') <= 90))\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a35475",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles.filter((col('titleType') == 'movie') & (col('runtimeMinutes') <= 90))\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa36904f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles.filter(((col('titleType') == 'movie') | (col('titleType') == 'tvSeries')) & (col('runtimeMinutes') <= 90))\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31472e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles.filter((col('titleType').isin('movie', 'tvSeries')) & (col('runtimeMinutes') <= 90))\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb86c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .filter(col('titleType').isin('movie','tvSeries'))\n",
    "    .filter(col('runtimeMinutes') <= 90)\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00c84da",
   "metadata": {},
   "source": [
    "#### Filtros Utilizando Expressões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b3c4a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .filter('titleType = \"movie\"')\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f16a64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .filter('titleType in (\"movie\", \"tvSeries\") and runtimeMinutes <= 90')\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c94aac0",
   "metadata": {},
   "source": [
    "#### Observações\n",
    "Quando nos referimos às colunas por meio da função `col()`, temos acesso à diversos métodos das colunas que podem ser utilizados para auxliar na filtragem do DataFrame. Alguns deles são:\n",
    "* `isin()`: checa se a coluna contém os valores listados na função.\n",
    "* `contains()`: utilizado para verificar se uma coluna de texto contém algum padrão especificado (não aceita regex). Aceita uma outra coluna de texto.\n",
    "* `like()`: utilizado para verificar se uma coluna de texto contém algum padrão especificado (não aceita regex). Funciona de forma similar ao \"LIKE\" do SQL.\n",
    "* `rlike()`: utilizado para verificar se uma coluna de texto contém algum padrão especificado (**aceita regex**). Funciona de forma similar ao \"RLIKE\" do SQL.\n",
    "* `startswith()`: utilizado para verificar se uma coluna de texto começa com algum padrão especificado (**aceita regex**).\n",
    "* `endswith()`: utilizado para verificar se uma coluna de texto termina com algum padrão especificado (**aceita regex**).\n",
    "* `between()`: checa se os valores da coluna estão dentro do intervalo especificado. Os dois lados do intervalo são inclusivos.\n",
    "* `isNull()`: retorna True se o valor da coluna é nulo\n",
    "* `isNotNull()`: retorna True se o valor da coluna não é nulo\n",
    "\n",
    "Outros métodos úteis:\n",
    "* `alias()/name()`: usado para renomear as colunas em operações como select() e agg()\n",
    "* `astype()/cast()`: usado para mudar o tipo das colunas. Aceita tanto um string como um tipo especificado pelo módulo pyspark.sql.types\n",
    "* `substr()`: utilizado para cortar um string com base em índices dos caracteres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc5e48d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .filter(col('primaryTitle').like('Avengers%'))\n",
    "    .filter(col('titleType') == 'movie')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6954e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .withColumn('startYear', col(\"startYear\").cast('int'))\n",
    "    .filter('startYear is not null')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1bdbca",
   "metadata": {},
   "source": [
    "### Ordenando o DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb3510",
   "metadata": {},
   "source": [
    "A ordenação do DataFrame pode ser feita utilizando as funções `orderBy()` ou `sort()`. Algumas funções auxiliares importante para serem usadas ao ordenar:\n",
    "* `asc()`: ordena a coluna de forma ascendente (default)\n",
    "* `desc()`ordena a coluna de forma decrescente\n",
    "* `asc_nulls_first() / desc_nulls_first()`: ordena a coluna de forma ascendente e decrescente, respectivamente, mantendo os campos nulos primeiro\n",
    "* `asc_nulls_last() / desc_nulls_last()`: ordena a coluna de forma ascendente e decrescente, respectivamente, mantendo os campos nulos por último"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e625a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee71dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "(\n",
    "    df_titles\n",
    "    .withColumn('startYear', col('startYear').cast('int'))\n",
    "    .orderBy('startYear')\n",
    "    .filter('titleType = \"movie\"')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81398b4e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc_nulls_first #desc_nulls_last\n",
    "\n",
    "(\n",
    "    df_titles\n",
    "    .withColumn('startYear', col('startYear').cast('int'))\n",
    "    .orderBy(desc_nulls_first('startYear'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ee1c2b",
   "metadata": {},
   "source": [
    "### Renomeando Colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69b1f00",
   "metadata": {},
   "source": [
    "Para renomear colunas, é utilizada a função `withColumnRenamed()`, da seguinte forma:\n",
    "\n",
    "```\n",
    "df.withColumnRenamed(\"nome_antigo\", \"nome_novo\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285736fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .withColumnRenamed('primaryTitle', 'nome_filme')\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510775cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .withColumnRenamed('primaryTitle', 'nome_filme')\n",
    "    .selectExpr('*', 'runtimeMinutes + 1')   \n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46cf472",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles.selectExpr('primaryTitle as nome_filme', 'titleType', 'startYear', 'runtimeMinutes')\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d4ec3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_renamed = df_titles\n",
    "for c in df_titles.columns:\n",
    "    df_renamed = df_renamed.withColumnRenamed(c, c + '_suffix')\n",
    "\n",
    "df_renamed.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe2d8b8",
   "metadata": {},
   "source": [
    "### Criando e Alterando Colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b3284",
   "metadata": {},
   "source": [
    "Para criar ou alterar colunas, é utilizada a função `withColumn()`, da seguinte forma:\n",
    "\n",
    "```\n",
    "df.withColumn(\"nome_da_coluna\", {expressão geradora de coluna})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8448851",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import upper\n",
    "\n",
    "(\n",
    "    df_titles\n",
    "    .select('tconst', 'primaryTitle', 'runtimeMinutes', )\n",
    "    .withColumn(\"primaryTitle_2\", upper('primaryTitle'))\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cbe4c8",
   "metadata": {},
   "source": [
    "#### Criando colunas a partir de constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc16e80a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "(\n",
    "    df_titles\n",
    "    .select('tconst', 'primaryTitle', 'runtimeMinutes', )\n",
    "    .withColumn(\"pais\", lit('Brasil'))\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877aa764",
   "metadata": {},
   "source": [
    "#### Criando colunas condicionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f5e73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, expr\n",
    "\n",
    "predicado = \"\"\"\n",
    "\n",
    "CASE WHEN runTimeMinutes <= 60 THEN 'curto'\n",
    "     WHEN runTimeMinutes > 60 AND runTimeMinutes < 120 THEN 'normal'\n",
    "     WHEN runTimeMinutes >= 120 THEN 'longo'\n",
    "     WHEN runTimeMinutes IS NULL THEN 'nulo'\n",
    "     ELSE 'Erro'\n",
    "END\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "(\n",
    "    df_titles\n",
    "    .select('tconst', 'primaryTitle', 'runtimeMinutes', )\n",
    "    .withColumn(\"runtimeMinutes\", col('runTimeMinutes').cast('int'))\n",
    "    .withColumn(\"categoria_runtime\", expr(predicado))\n",
    "    .filter('runTimeMinutes > 60')\n",
    "    .show(25)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ad0856",
   "metadata": {},
   "source": [
    "## Trabalhando com Diferentes Tipos de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798fc43c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d1677c",
   "metadata": {},
   "source": [
    "### Valores Numéricos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b4c0b2",
   "metadata": {},
   "source": [
    "* `round()`: arredonda o valor numérico\n",
    "* `ceil()`: arredonda o valor numérico para o maior inteiro mais próximo\n",
    "* `floor()`: arredonda o valor numérico para o menor inteiro mais próximo\n",
    "* `sqrt()`: retorna a raiz quadrada do valor\n",
    "* `exp()`: retorna a exponencial do valor\n",
    "* `log()`: retorna a logaritmo natural do valor\n",
    "* `log10()`: retorna a logaritmo na base 10 do valor\n",
    "* `greatest()`: retorna o maior valor dentre os valores das colunas. Análogo ao `max()`, mas entre colunas\n",
    "* `least()`: retorna o menor valor dentre os valores das colunas. Análogo ao `min()`, mas entre colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b7a80",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0879803d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .withColumn('runtimeMinutes', f.col('runtimeMinutes').cast('int'))\n",
    "    .withColumn('random_normal', f.randn(123))\n",
    "    .withColumn('dummy_division', f.col('runtimeMinutes') / f.col('random_normal'))\n",
    "    .withColumn('round_example', f.round(f.col('dummy_division'), 3))\n",
    "    .withColumn('ceil_example', f.ceil(f.col('dummy_division')))\n",
    "    .withColumn('floor_example', f.floor(f.col('dummy_division')))\n",
    "    .withColumn('greatest_example', f.greatest(f.col('random_normal'), f.col('runtimeMinutes'), f.lit(15)))\n",
    "    .withColumn('least_example', f.least(f.col('random_normal'), f.col('runtimeMinutes'), f.lit(-15)))\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a82dead",
   "metadata": {},
   "source": [
    "### Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1367d82",
   "metadata": {},
   "source": [
    "* `upper()`: retorna o string em letras maiúsculas\n",
    "* `lower()`: retorna o string em letras minúsculas\n",
    "* `initcap()`: retorna a primeira letra de cada palavra no string em letras maiúsculas\n",
    "* `trim()`: retira os espaços em branco do início e do final do string\n",
    "* `ltrim() / rtrim()`: retira os espaços em branco do início e do final do string, respectivamente\n",
    "* `lpad() / rpad()`: acrescenta um caractere no início e no final do string, respectivamente, até que o string tenha um determinado comprimento\n",
    "* `length()`: retorna o comprimento do string, em quantidade de caracteres\n",
    "* `split()`: quebra o string a partir de um padrão e retorna um array com os string resultantes\n",
    "* `concat()`: concatena uma ou mais colunas de string\n",
    "* `concat_ws()`: concatena uma ou mais colunas de string, com um separador entre elas\n",
    "* `regexp_extract()`: retorna um match no string a partir de um padrão regex\n",
    "* `regexp_replace()`: substitui um mtach no strinf a partir de um padrão regex com outros caracteres\n",
    "* `substring()`: retorna os caracteres do string que estão entre dos indices especificados. Análogo a `f.col().substring()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bcfc64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .withColumn('primaryTitle', f.initcap(f.col('primaryTitle')))\n",
    "    .withColumn('titleType', f.trim(f.initcap(f.col('titleType'))))\n",
    "    .withColumn('genres_array', f.split(f.col('genres'), ','))\n",
    "    .withColumn('num_const', f.substring(f.col('tconst'), 3, 7))\n",
    "    .withColumn('full_name', f.concat_ws(' / ', f.col('primaryTitle'), f.col('originalTitle')))\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260cf87",
   "metadata": {},
   "source": [
    "### Datas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7174d13a",
   "metadata": {},
   "source": [
    "* `add_months()`: retorna a data depois de adicionar \"x\" meses\n",
    "* `months_between()`: retorna a diferença entre duas datas em meses\n",
    "* `date_add()`: retorna a data depois de adicionar \"x\" dias\n",
    "* `date_sub()`: retorna a data depois de subtrair \"x\" dias\n",
    "* `next_day()`: retorna o dia seguinte de alguma data\n",
    "* `datediff()`: retorna a diferença entre duas datas em dias\n",
    "* `current_date()`: retorna a data atual\n",
    "* `dayofweek() / dayofmonth() / dayofyear()`: retorna o dia relativo à semana, ao mês e ao ano, respectivamente\n",
    "* `weekofyear()`: retorna a semana relativa ao ano\n",
    "* `second() / minute() / hour()`: retorna os segundos, os minutos e as horas de uma coluna de date-time, respectivamente\n",
    "* `month() / year()`: retorna o mês e o ano de uma coluna de data, respectivamente\n",
    "* `last_day()`: retorna o último dia do mês do qual a data considerada pertence\n",
    "* `to_date()`: transforma a coluna no tipo data (t.DateType())\n",
    "* `trunc()`: formata a data para a unidade especificada\n",
    "    * `year`: \"{ano}-01-01\"\n",
    "    * `month`: \"{ano}-{mes}-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5c9c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .filter('titleType = \"movie\"')\n",
    "    .withColumn('data_ano', f.to_date(f.col('startYear'), 'yyyy'))\n",
    "    .withColumn('mes', f.month(f.col('data_ano')))\n",
    "    .withColumn('dia', f.dayofmonth(f.col('data_ano')))\n",
    "    .withColumn('hoje', f.current_date())\n",
    "    .withColumn('data_mes', f.trunc(f.col('hoje'), 'month'))\n",
    "    .withColumn('ultimo_dia_mes', f.last_day(f.col('data_ano')))\n",
    "    .withColumn('idade_filme_dias', f.datediff(f.col('hoje'), f.col('data_ano')))\n",
    "    .withColumn('idade_filme_meses', f.floor(f.months_between(f.col('hoje'), f.col('data_ano'))))\n",
    "    .withColumn('idade_filme_anos', f.floor(f.col('idade_filme_dias') / 365))\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054dc7ba",
   "metadata": {},
   "source": [
    "### Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46555560",
   "metadata": {},
   "source": [
    "* `array()`: constrói um array com as colunas selecionadas\n",
    "* `flatten()`: transforma um array de arrays em um unico array\n",
    "* `explode()`: retorna uma nova linha para cada elemento no array \n",
    "* `size()`: retorna o número de elementos no array\n",
    "* `sort_array()`: ordena os elementos do array, de forma crescente ou decrescente\n",
    "* `reverse()`: reverte a ordem dos elementos de um array\n",
    "* `array_distinct()`: remove elementos duplicados do array\n",
    "* `array_contains()`: verifica se o array contém o elemento especificado\n",
    "* `arrays_overlap()`: partir de 2 colunas de arrays, verifica se elas tem algum elemento em comum, retornando True ou False\n",
    "* `array_union()`: a partir de 2 colunas de arrays, retorna um array com os elementos unidos das duas colunas, sem duplicatas\n",
    "* `array_except()`: a partir de 2 colunas de arrays, retorna um array com os elementos que estão em uma coluna mas não estão na outra, sem duplicatas\n",
    "* `array_intersect()`: a partir de 2 colunas de arrays, retorna um array com os elementos que nas duas colunas, sem duplicatas\n",
    "* `array_join()`: retorna um string após concatenar os elementos do array usando o delimitador especificado\n",
    "* `array_max() / array_min()`: retorna o máximo e o mínimo valor do array, respectivamente\n",
    "* `array_remove()`: remove todos os elementos do array que são iguais ao valor especificado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53de54e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .filter('titleType = \"movie\"')\n",
    "    .withColumn('genres_array', f.split(f.col('genres'), ','))\n",
    "#     .withColumn('first_genre', f.col('genres_array')[0])\n",
    "#      .withColumn('second_genre', f.col('genres_array').getItem(1))\n",
    "#      .withColumn('genres_string', f.array_join(f.col('genres_array'), ','))\n",
    "#      .withColumn('n_genres', f.size(f.col('genres_array')))\n",
    "#      .filter('n_genres >= 3')\n",
    "    .withColumn('genres_unico', f.explode(f.col('genres_array')))\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9114ec7",
   "metadata": {},
   "source": [
    "### Nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b3db6",
   "metadata": {},
   "source": [
    "* `drop()`: retira do DataFrame as linhas com nulos, com base no que foi passado para o argumento how\n",
    "    * any (default): retira todas as linhas com pelo menos um valor nulo nas colunas\n",
    "    * all: somente retira as linhas com todos os valores nulos nas colunas\n",
    "* `fill()`: preenche os valores nulos no DataFrame com uma constante, passada pelo usuário\n",
    "* `replace()`: substitui o valor (não somente os valores nulos) por algum outro passado pelo usuário\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23008d00",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .replace('\\\\N', None, subset=['startYear', 'endYear', 'runtimeMinutes'])\n",
    "    .filter(\"startYear is null and runtimeMinutes is not null\")\n",
    "#     .na.fill('Não se sabe', subset=['startYear'])\n",
    "#     .orderBy(f.asc_nulls_first('endYear'))\n",
    "#     .na.drop(subset=['startYear'])\n",
    "    .withColumn('coalesce_test', f.coalesce(f.col(\"startYear\"), f.col(\"runtimeMinutes\"), f.lit('Sem ano')))\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12862a21",
   "metadata": {},
   "source": [
    "### Agregação e Agrupamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cf83b9",
   "metadata": {},
   "source": [
    "O agrupamento dos DataFrames é feito por meio da função **`groupby()`**. Essa função deve ser sucedida pela função de agregação `agg()`, de pivotação `pivot()` ou `count()`. \n",
    "\n",
    "---\n",
    "\n",
    "A função **`agg()`** aplica uma função de agregação no DataFrame. Se precedida por `groupby()`, realiza a agregação dentro dos grupos esabelecidos.\n",
    "Algumas das funções de agregação mais comuns:\n",
    "* `sum()`: retorna a soma os valores da coluna\n",
    "* `sumDistinct()`: retorna a soma os valores distintos da coluna\n",
    "* `max() / min()`: retorna o mínimo e o máximo da coluna, respectivamente\n",
    "* `avg() / mean()`: retorna a média dos valores da coluna\n",
    "* `percentile_approx()`: retorna o percentil da coluna, comaproximação. Para trazer a mediana exata, usar: `percentile_approx(f.col('column'), 0.5, lit(1000000))`\n",
    "* `stddev()`: retorna o desvio padrão dos valores da coluna\n",
    "* `count()`: retorna a contagem de linhas\n",
    "* `countDistinct()`: retorna a contagem de valores distintos da coluna\n",
    "* `first() / last()`: retorna o primeiro e o último valor da coluna no agrupamento, respectivamente. Interessante de ser utilizada em conjunto com o argumento `ignoreNulls=True`.\n",
    "* `collect_list()`: retorna os valores do agrupamento em uma lista, com duplicações\n",
    "* `collect_set()`: retorna os valores do agrupamento em uma lista, sem duplicações (desordenado)\n",
    "\n",
    "**Obs**: O spark ignora os valores nulos para calcular as agregações, com exceção da função `count()`.\n",
    "\n",
    "---\n",
    "\n",
    "A função **`pivot`** é utilizada para passar valores de uma linha para as colunas, realizando uma agregação. Deve ser sucedido por uma função de agregação utilizando `agg()`. Pode utilizar qualquer uma das funções de agregação anteriores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d14f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles_subset = (\n",
    "    df_titles\n",
    "    .filter(\"cast(startYear as int) >= 2000\")\n",
    "    .sample(fraction = 0.5)\n",
    "    .withColumn('genre', f.split('genres', ',').getItem(0))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420eb083",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles_subset.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15622ff3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles_subset\n",
    "    .agg(f.countDistinct('genre').alias('distinct_genres'),)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3928561c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles_subset\n",
    "    .withColumn('runtimeMinutes', f.col('runtimeMinutes').cast('date'))\n",
    "    )\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a972ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles_subset.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9122b190",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles_subset\n",
    "    .withColumn('runtimeMinutes', f.col('runtimeMinutes').cast('int'))\n",
    "    .select('runtimeMinutes')\n",
    "    .describe()\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e99220c",
   "metadata": {},
   "source": [
    "#### Agrupamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f60b41",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles_subset.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1773e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles_subset\n",
    "    .groupby('genre', 'startYear')\n",
    "    .agg(f.mean('runtimeMinutes').alias('mean_runtimeMinutes'),)\n",
    "    .orderBy('startYear', f.col('mean_runtimeMinutes').desc())\n",
    "    .filter('startYear = 2021')\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f978aa42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles_subset\n",
    "    .groupby('genre')\n",
    "    .agg(f.collect_set(f.col('titleType')).alias('lista_tipos_titulo'),\n",
    "         f.countDistinct(f.col('titleType')).alias('n_distinct')\n",
    "        )\n",
    "    .withColumn('tipos_filmes', f.explode(f.col('lista_tipos_titulo')))\n",
    "    .select('genre', 'tipos_filmes')\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7243553",
   "metadata": {},
   "source": [
    "#### Pivotação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9971f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles_subset.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc723650",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles_subset\n",
    "    .drop('genre')\n",
    "    .withColumn('genres', f.explode(f.split(f.col('genres'), ',')))\n",
    "    .groupby('startYear')\n",
    "    .pivot('genres')\n",
    "    .agg(f.mean('runtimeMinutes'))\n",
    "    .na.fill(0)\n",
    "    .orderBy('startYear')\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225dba39",
   "metadata": {},
   "source": [
    "### Window Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59f5b70",
   "metadata": {},
   "source": [
    "Window functions são funções que realizam cálculos similares à uma agregação, mas que não resultam em um DataFrame agregado. Ao invés disso, os resultados são colocados em uma nova coluna, segundo a partição (ou agrupamento) especificado. \n",
    "Exemplos mais comuns:\n",
    "* `row_number()`\n",
    "* `rank() / dense_rank() / percent_rank()`\n",
    "* `lag()`\n",
    "* `cume_dist()`\n",
    "* `collect_list() / collect_set()`\n",
    "* Demais funções de agregação, com exceção de `countDistinct()`\n",
    "\n",
    "Para usar as funções dessa forma, devemos criar uma janela (window) da seguinte forma:\n",
    "\n",
    "```{python}\n",
    "from pyspark.sql.window import Window\n",
    "w = Window.partitionBy({columns}).orderBy({columns}).rowsBetween({lower}, {upper})\n",
    "```\n",
    "\n",
    "* **`partitionBy()`**: agrupamento em que os cálculos serão realizados. É análogo ao `groupBy()`.\n",
    "* **`orderBy`**: algumas funções como `row_number()` e `lag()` dependem da ordenação das linhas do agrupamento. Essa função é usada para especificar essa ordem.\n",
    "* **`rowsBetween()`**: esse método é usado para especificar janelas deslizantes. A partir dele é possível definir um intervalo de linhas, relativas à linha atual, em que a função vai ser aplicada. Caso isso não seja especificado, as operações são realizadas em todo o grupo. Muito útil para construir **médias móveis**. Os seguintes objetos ajudam na constrção desse intervalo:\n",
    "  * `Window.currentRow`: define a linha para qual o valor está sendo calculado como um dos limites de cálculo\n",
    "  * `Window.unboundedPreceding`: define que não há limites para as linhas anteriores à linha para qual o valor está sendo calculado, isto é, a função irá considerar todas as linhas do grupo que já passaram. Deve ser usado no primeiro argumento (start).\n",
    "  * `Window.unboundedFollowing`: define que não há limites para as linhas posteriores à linha para qual o valor está sendo calculado, isto é, a função irá considerar todas as linhas do grupo que ainda não passaram. Deve ser usado no segundo argumento (end).\n",
    "\n",
    "Depois disso, basta utilizar a função `over()` para indicar que aquela função deve ser realizada na janela.  Exemplo:\n",
    "```\n",
    "df.withColumn('rn', f.row_number().over(w))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01ec116",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb91cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles_subset = (\n",
    "    df_titles\n",
    "    .filter(\"cast(startYear as int) >= 2000\")\n",
    "    .sample(fraction = 0.5)\n",
    "    .withColumn('genre', f.split('genres', ',').getItem(0))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f20bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles_subset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ecb3b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles_subset.withColumn('genre', f.split('genres', ',').getItem(0)).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87948f23",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w = Window.partitionBy('genre').orderBy(f.desc('startYear'))\n",
    "(\n",
    "    df_titles_subset\n",
    "    .withColumn('genre', f.split('genres', ',').getItem(0))\n",
    "    .withColumn('startYear', f.col('startYear').cast('int'))\n",
    "    .filter('startYear >= 2021')\n",
    "    .withColumn('rn', f.percent_rank().over(w))\n",
    "    .limit(25)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019fc1e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w = Window.partitionBy('titleType', 'startYear')\n",
    "(\n",
    "    df_titles_subset\n",
    "    .withColumn('genre', f.split('genres', ',').getItem(0))\n",
    "    .withColumn('runtimeMinutes', f.col('runtimeMinutes').cast('int'))\n",
    "    .withColumn('total_minutes', f.sum(f.col('runtimeMinutes')).over(w))\n",
    "    .withColumn('mean_minutes', f.mean(f.col('runtimeMinutes')).over(w))\n",
    "    .withColumn('relative_minutes', f.col('runtimeMinutes') / f.col('total_minutes'))\n",
    "    .filter('runtimeMinutes is not null') \n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35d814",
   "metadata": {},
   "source": [
    "### Cálculo de média móvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41201669",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w = Window.partitionBy('titleType').orderBy('startYear').rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "(\n",
    "    df_titles_subset\n",
    "    .withColumn('runtimeMinutes', f.col('runtimeMinutes').cast('int'))\n",
    "    .groupby('titleType', 'startYear')\n",
    "    .agg(f.expr('mean(runtimeMinutes) as media_minutos'))\n",
    "    .orderBy('titleType', 'startYear')\n",
    "    .withColumn('meadia_movel_3anos', f.round(f.mean('media_minutos').over(w), 3))\n",
    "    .limit(15)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d92e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#f.round(((50.256494 + 51.645619 + 51.713004)/3), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a40b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#(49.186983 + 50.358881 + 52.182771 + 49.007634 + 55.584795)/5 == 51.264"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14471672",
   "metadata": {},
   "source": [
    "#### Usando uma Window para calcular os distintos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba0adb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w = Window.partitionBy('titleType', 'startYear')\n",
    "(\n",
    "    df_titles\n",
    "    .withColumn('lista_cnae', f.countDistinct(f.col('tconst')).over(w))\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56802cfb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w = Window.partitionBy('titleType', 'startYear')\n",
    "(\n",
    "    df_titles_subset\n",
    "    .withColumn('lista_titulos', f.collect_set(f.col('tconst')).over(w))\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c415bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w = Window.partitionBy('titleType', 'startYear')\n",
    "(\n",
    "    df_titles_subset\n",
    "    .withColumn('lista_titulos', f.collect_set(f.col('tconst')).over(w))\n",
    "    .withColumn('titulos_distintos', f.size(f.col('lista_titulos')))\n",
    "    .select('titleType', 'startYear', 'titulos_distintos')\n",
    "    .orderBy(f.col('titulos_distintos').desc())\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53926a87",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles_subset\n",
    "    .groupby('titleType', 'startYear')\n",
    "    .agg(f.countDistinct(f.col('tconst')).alias('titulos_distintos'))\n",
    "    .orderBy(f.col('titulos_distintos').desc())\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6199689e",
   "metadata": {},
   "source": [
    "#### Usando Windows para evitar Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f84a7b",
   "metadata": {},
   "source": [
    "Objetivo: Titulos mais recentes por genero\n",
    "\n",
    "Caminho natural:\n",
    "```\n",
    "df1 = df_titles.groupby('genre').agg(f.max(f.col('startYear').alias('startYear'))\n",
    "df2 = df_titles.join(df1, ['genre', 'startYear'])\n",
    "```\n",
    "Alternativa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d333ea1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w = Window.partitionBy('genre')\n",
    "(\n",
    "    df_titles_subset\n",
    "    .withColumn('max_data', f.max(f.col('startYear')).over(w))\n",
    "    .filter('startYear = max_data')\n",
    "    .limit(10)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7a1eca",
   "metadata": {},
   "source": [
    "### Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e342c8",
   "metadata": {},
   "source": [
    "Os joins no pyspark são especificados pela função `join()`, da seguinte forma:\n",
    "\n",
    "```\n",
    "df1.join(df2, {key_columns}, {join_type})\n",
    "```\n",
    "\n",
    "* `key_columns`: colunas que vão ser utilizadas para fazer a junção das tabelas. Pode ser especificada como\n",
    "    * Um único string -> só uma coluna é chave, mesmos nomes nas duas tabelas\n",
    "    * Uma lista de string ou de colunas (`col()`) -> mais de uma coluna é chave, mesmos nomes nas duas tabelas\n",
    "    * Com nomes diferentes, é necessário fazer uma especificação do tipo: `f.col(column1) == f.col(column2)`. Caso existam mais de uma coluna como chave, essas especificações devem ser colocadas em uma lista.\n",
    "* `join_type`: o tipo de join a ser realizado. As opções são:\n",
    "    * `inner (default)`: INNER JOIN do SQL\n",
    "    * `outer / full / fullouter / full_outer`: : FULL OUTER JOIN do SQL\n",
    "    * `left / leftouter / left_outer`: : LEFT JOIN do SQL\n",
    "    * `right / rightouter / right_outer`: : RIGHT JOIN do SQL\n",
    "    * `semi / leftsemi / left_semi`: realiza um LEFT JOIN do SQL e retorna somente as colunas do DataFrame da esquerda que também estão no DataFrame da Direita\n",
    "    * `anti / leftanti / left_anti`: realiza um LEFT JOIN do SQL e retorna somente as colunas do DataFrame da esquerda que não estão no DataFrame da Direita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34957393",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8968/2030544596.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m df_ratings = (spark.read\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimdb_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'title_ratings.tsv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "df_ratings = (spark.read\n",
    "    .format('csv')\n",
    "    .options(sep='\\t', header=True)\n",
    "    .load(imdb_path + 'title_ratings.tsv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38291b4b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ratings.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12184d7e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e6be42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b1596",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b033f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .join(df_ratings, 'tconst', 'left')\n",
    "    .filter('averageRating is null')\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e63ad52",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .withColumnRenamed('tconst', 'id_title')\n",
    "    .join(df_ratings, f.col('tconst') == f.col('id_title'))\n",
    "    .withColumn('averageRating', f.expr('averageRating + 1'))\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43519981",
   "metadata": {},
   "source": [
    "#### Utilizando semi e anti join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4a599",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ratings.select('tconst').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328380c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.select('tconst').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59038bde",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .join(df_ratings, 'tconst', 'semi')\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e671991",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .join(df_ratings, 'tconst', 'anti')\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b9357",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "6961705 + 1174232 == df_titles.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e973cdd",
   "metadata": {},
   "source": [
    "### Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c7efe2",
   "metadata": {},
   "source": [
    "Existem três formas de unir DataFrames no pyspark:\n",
    "* `union() / unionAll()`: empilha os DataFrames, preservando linhas duplicadas. As colunas são unidas por posição, e por isso a ordem delas deve ser a mesma entre os dois DFs.\n",
    "* `unionByName()`: empilha os DataFrames, preservando linhas duplicadas. As colunas são unidas por nome, e por tanto não precisam estar ordenadas da mesma forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f844e8cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f022f134",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865c402",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df_titles.sample(fraction = 0.5)\n",
    "df2 = df_titles.join(df1, ['tconst'], 'anti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bda54d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d5b97",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd3edad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1.union(df2).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2928e1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df_titles.sample(fraction = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b075626",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f631d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df3.union(df3).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b064a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df3.union(df3).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4563624",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df2.select(df2.columns[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a9280",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951fc9db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb632b0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1.union(df2).filter('genres rlike \"[0-9]\"').limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce1027d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1.unionByName(df2).filter('genres rlike \"[0-9]\"').limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f49ea2",
   "metadata": {},
   "source": [
    "### User Defined Functions (UDFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eee98f",
   "metadata": {},
   "source": [
    "Em algumas situações é necessário criar/alterar uma coluna utilizando uma operação não implementada na biblioteca padrão. Para isso, é possível utilzar funções definidas pelo usuário (UDFs) por meio da função `udf()`.\n",
    "\n",
    "**Importante**: As udfs não são otimizadas para serem executadas em paralelo, e por isso podem representar um gargalo na na aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "084b0eeb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e9f845f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaaceou'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unidecode('àáâçéõü')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a654447b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def unidecode_function(string):\n",
    "    if not string:\n",
    "        return None\n",
    "    else:\n",
    "        return unidecode(string)\n",
    "\n",
    "unidecode_udf = f.udf(unidecode_function, returnType=StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b4df18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .filter(f.col('primaryTitle').rlike('à|á|â|ç|é|õ|ü|ó'))\n",
    "    .withColumn('cleaned_string', unidecode_udf(f.col('primaryTitle')))\n",
    "    .select('primaryTitle', 'cleaned_string')\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f9853",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del unidecode_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a984f67",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@f.udf(returnType=t.StringType())\n",
    "def unidecode_udf(string):\n",
    "    if not string:\n",
    "        return None\n",
    "    else:\n",
    "        return unidecode(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0114e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_titles\n",
    "    .filter(f.col('primaryTitle').rlike('à|á|â|ç|é|õ|ü'))\n",
    "    .withColumn('cleaned_string', unidecode_udf(f.expr('primaryTitle')))\n",
    "    .select('primaryTitle', 'cleaned_string')\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ba9aa",
   "metadata": {},
   "source": [
    "### Criando Métodos Customizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa03ca54",
   "metadata": {},
   "source": [
    "Em algumas situações, é interessante que realizemos uma operação sobre um DataFrame que não está implementada. Além disso, pode ser que seja necessário (ou do desejo do desenvolvedor) utilizar essa operação de forma encadeada.\n",
    "\n",
    "Para resolver esse problema, podemos utilizar o método `.transform()`. Funciona da seguinte maneira:\n",
    "\n",
    "1) Definir uma função do python da seguinte forma:\n",
    "\n",
    "```\n",
    "def f(args):\n",
    "  def _(df):\n",
    "    {operacoes sob o DataFrame}\n",
    "    return df\n",
    "  return _\n",
    "```\n",
    "2) Depois de definida a função, ela pode ser chamada da seguinte forma:\n",
    "\n",
    "\n",
    "```\n",
    "df.transform(f(args))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d3bf74",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def processing(df):\n",
    "    ...\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613aacea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "df = (\n",
    "    df.select().filter()\n",
    ")\n",
    "df = processing(df)\n",
    "df = (\n",
    "    df.groupby().agg()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cdca9f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "df = (\n",
    "    df.select()\n",
    "    .filter()\n",
    "    .transform(processing(df))\n",
    "    .groupby()\n",
    "    .agg()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf4a47b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def renamer(dict):\n",
    "    def _(df):\n",
    "        for c, n in dict.items():\n",
    "            df = df.withColumnRenamed(c, n)\n",
    "        return df\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d71741",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10329edd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    \"tconst\": 'id_title',\n",
    "    \"titleType\": 'tipo_title',\n",
    "    'primaryTitle': 'nome_primario',\n",
    "    'originalTitle': 'nome_original',\n",
    "    'isAdult': \"idc_adult_title\",\n",
    "    'startYear': 'ano_lancamento',\n",
    "    'endYear': 'ano_encerramento',\n",
    "    'runtimeMinutes': 'duracao_minutos',\n",
    "    'genres': 'generos',\n",
    "}\n",
    "\n",
    "(\n",
    "    df_titles\n",
    "    .transform(renamer(rename_dict))\n",
    "    .limit(5)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af6d03",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def transform(self, f):\n",
    "    return f(self)\n",
    "\n",
    "DataFrame.transform = transform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
